{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../MCMC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable, Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import batch_utils\n",
    "import plot_utils\n",
    "import McNeuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = McNeuron.NeuronCollection.load_data('/Users/pavanramkumar/Dropbox/HG-GAN/03-Data/All Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# training_data = pickle.load(open('/Users/pavanramkumar/Dropbox/HG-GAN/03-Data/pyramidal_neuron_n40_parent_id.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_nodes = 40\n",
    "# g = training_data['geometry']['n'+str(n_nodes)]\n",
    "# m = training_data['morphology']['n'+str(n_nodes)]\n",
    "# n_samples = g.shape[0]\n",
    "\n",
    "# not_nan_list = list()\n",
    "# for n in range(n_samples):\n",
    "#     if ~np.any(np.isnan(g[n])):\n",
    "#         not_nan_list.append(n)\n",
    "# not_nan_list = np.array(not_nan_list)\n",
    "# g = g[not_nan_list, :, :]\n",
    "# m = m[not_nan_list, :]\n",
    "# training_data['geometry']['n'+str(n_nodes)] = g\n",
    "# training_data['morphology']['n'+str(n_nodes)] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_neuron = McNeuron.Neuron(input_file=training_data['X'][0][:, :],\n",
    "                                 input_format=\"Matrix of swc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408,)\n",
      "(3, 408)\n"
     ]
    }
   ],
   "source": [
    "print example_neuron.branch_order.shape\n",
    "print example_neuron.location.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = example_neuron.location[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['X'][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_nodes = list()\n",
    "for i in range(len(training_data['X'])):\n",
    "    n_nodes.append(training_data['X'][i].shape[0])\n",
    "n_nodes = np.array(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94552424957728554"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(n_nodes <= 5000) / np.float(n_nodes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFkCAYAAAAKf8APAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqmNAkSRJ1TGgSJKk6hhQJElSdf4/Ewv7VXohZBMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x215e2a4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(n_nodes, 125)\n",
    "plt.xlim([0, 5000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'pyramidal': 14013, 'Unknown neurotransmitter': 7237, 'Not reported': 6670, 'glutamatergic': 6092, 'GABAergic': 4474, 'cholinergic': 3384, 'granule': 2308, 'serotonergic': 2212, 'Nitrergic': 2044, 'medium spiny': 1534, 'ganglion': 1485, 'dopaminergic': 870, 'basket': 542, 'Motoneuron': 407, 'Parachromaffin': 401, 'tangential': 338, 'Aspiny': 327, 'octopaminergic': 265, 'uniglomerular projection': 237, 'transmedulla': 235, 'stellate': 214, 'Multidendritic-dendritic arborization (DA)': 211, 'Pyramidal-like': 192, 'somatic': 184, 'Martinotti': 148, 'projection': 147, 'direction sensitive': 127, 'astrocyte': 117, 'Parvalbumin (PV)-positive': 110, 'neurogliaform': 106, 'Type I': 91, 'prion protein (PrP) promoter-positive': 81, 'Fast-spiking': 79, 'Oligodendrocyte': 78, 'Neuropeptide Y (NPY)-positive': 77, 'Cajal-Retzius': 73, 'olivocerebellar': 68, 'Intersubnuclear neuron': 68, 'bitufted': 67, 'Type II': 65, 'thalamocortical': 65, 'bipolar': 64, 'ivy/neurogliaform': 58, 'Golgi': 56, 'Chandelier': 56, 'double bouquet': 54, 'Somatostatin (SOM) containing cell': 53, 'Lugaro': 50, 'multipolar': 46, 'Purkinje': 43, 'Inhibitory': 42, 'perisomatic targeting': 41, 'L1': 40, 'pre-motor': 39, 'Mi1': 37, 'Spiny': 36, 'dendritic targeting': 36, 'Excitatory': 35, 'periglomerular': 33, 'GAD65-expressing': 33, 'Neuroblast': 33, 'scratch-activated': 31, 'T4out': 31, 'target-selective descending': 30, 'Calretinin (CR)-positive': 29, 'von Economo neuron': 29, 'T4': 29, 'Extraverted': 28, 'inspiratory': 28, 'spinocerebellar': 28, 'Non-cholinergic': 26, 'mitral': 25, 'tripolar': 25, 'cone': 25, 'Mi9': 23, 'R7': 22, 'Mi4': 22, 'tyrosine-hydroxylase-positive': 21, 'touch receptor': 21, 'R8': 19, 'L5': 19, 'third order pheromone responsive': 19, 'L2': 19, 'Calbindin (CB)-positive': 18, 'T2a': 18, 'Dm8': 17, 'Pharyngeal': 17, 'L3': 17, 'Horizontal': 16, 'T2': 16, 'External tufted cell (ETC)': 15, 'C2': 15, 'Cholecystokinin (CCK)-positive': 14, 'Schaffer-collateral associated': 14, 'T3': 14, 'Dm3': 14, 'T4c': 13, 'Dm2': 13, 'Pm2': 13, 'C3': 13, 'CT1': 13, 'L4': 13, 'class IV': 12, 'modulated': 12, 'Pm2-like': 12, 'T4b': 12, 'Renshaw': 12, 'Non-glutamatergic': 12, 'Mi15': 11, 'Ring': 11, 'amacrine': 11, 'deep short axon': 11, 'oriens-lacunosum moleculare': 11, 'T1': 11, 'bistratified': 11, 'T4a': 10, 'Mi13': 10, 'T4d': 10, 'interneuron-specific interneuron': 9, 'Pm1': 9, 'Dm4': 9, 'Total molecular layer projecting': 9, 'tufted': 8, 'lch5-2/lch5-4': 8, 'Local circuit neuron': 8, 'Ia inhibitory': 8, 'sternzelle': 8, 'Dm6': 8, 'Dm10': 8, 'A00c': 8, 'Gustatory': 8, 'Mi10': 7, 'inverted': 7, 'Dm1': 7, 'Crab-like': 7, 'Amphid': 6, 'semilunar granule': 6, 'plane polarized targeting': 6, 'Dm9': 6, 'LaWF1': 6, 'axonless': 6, 'Non-fast spiking': 6, 'Dm5-like': 5, 'vertical': 5, 'Dm': 5, 'Mi2': 5, 'Muscarinic-responsive': 5, 'Dorsal root afferent fiber collateral': 5, 'Perforant pathway-associated': 5, 'Trilaminar': 4, 'A05q': 4, 'A02m/A02n': 4, 'vchA/vchB': 4, 'Pm-type unknown-1': 4, 'lch5-5': 4, 'lch5-3': 4, 'lch5-1': 4, 'A08m': 4, 'Basin-4': 4, 'Basin-3': 4, 'Basin-2': 4, 'Descending': 4, 'Basin-1': 4, 'Dm3-like': 3, 'Dm7': 3, 'Lawf2': 3, 'Choline acetyltransferase (ChAT)-positive': 3, 'olfactory': 3, 'Y6': 3, 'A10f': 2, 'A10a': 2, 'A10l': 2, 'A10j': 2, 'Integrative ring': 2, 'A23g': 2, 'Mi14': 2, 'non-renshaw': 2, 'Ipsigoro': 2, 'A03o': 2, 'T08x': 2, 'Telephone': 2, 'Dm1-like': 2, 'TePn04': 2, 'Reticulospinal': 2, 'A05e': 2, 'A19c': 2, 'SEZ DN 1': 2, 'Telegoro': 2, 'Mi': 2, 'A29b': 2, 'A02o': 2, 'internal tufted': 2, 'T05t': 2, 'Small': 2, 'A08d': 2, 'A12m': 2, 'A12q': 2, 'Non-basket': 2, 'A08y': 2, 'A08x': 2, 'fusiform': 2, \"v'ch\": 2, 'Ring/Pharynx': 2, 'Goro': 2, 'Serotonin receptor type 3A (5-HT3)-positive': 2, 'Y4': 2, 'Ipsiphone': 2, 'Dm7-like': 1, \"Shepherd's crook neuron\": 1, 'Mi11-like': 1, 'Septum-projecting': 1, 'Mi-type unknown-1': 1, 'Dm1/6-like': 1, 'HICAP': 1, 'Pm': 1, 'Olt-like': 1, 'Pm-type unknown-2': 1, 'Vasoactive Intestinal Peptide (VIP)-positive': 1, 'MOPP': 1, 'Dm-type unknown-2': 1, 'Dm-type unknown-1': 1, 'Cannabinoid receptor (CB1R)-positive': 1, 'Mt5-like': 1, 'A00b2': 1, 'tritufted': 1, 'bursting': 1, 'oriens-alveus': 1, 'Mi3-like': 1, 'Mt11-like': 1, 'Mt3-like': 1, 'Nonpyramidal': 1, 'oriens-oriens': 1, 'Mt4-like': 1, 'Somatostatin (SOM)-positive': 1, 'A00b': 1, 'Regulator of calcineurin 2 (Rcan2)-postive': 1, 'Back-Projecting': 1, 'HIPP': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print Counter(training_data['Y']['Secondary Cell Class'])\n",
    "# print np.sort(Counter(training_data['Y']['Secondary Cell Class']).values())[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = 100\n",
    "# random_projection = np.random.randn(dim, 3)\n",
    "random_projection = np.eye(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_node(neuron, node, random_projection):\n",
    "    z = neuron.location[:, node]\n",
    "    z = np.dot(random_projection, z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def continue_reduce(z1, z2, context):\n",
    "    return z1 + z2 + context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def branch_reduce(z1, z2, z3, context):\n",
    "    return z1 + z2 + z3 + context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tracker(context, z, buffer_):\n",
    "    next_context = np.tanh(context + np.mean(z1) + np.mean(buffer_))\n",
    "    return next_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node = example_neuron.branch_order.shape[0] - 1\n",
    "stack = list()\n",
    "# stack.append(encode_node(example_neuron, node, random_projection))\n",
    "context = 0.\n",
    "\n",
    "while (node >= 1):\n",
    "    \n",
    "    # Read buffer\n",
    "    z_buffer = encode_node(example_neuron, node, random_projection)\n",
    "    \n",
    "    # Update tracker\n",
    "    context = 0. # tracker(context, stack[-1], z1)\n",
    "    \n",
    "    # Leaf node\n",
    "    if(example_neuron.branch_order[node] == 0):\n",
    "        stack.append(z_buffer)\n",
    "        \n",
    "    # Node with one parent\n",
    "    if(example_neuron.branch_order[node] == 1):\n",
    "        z_stack1 = stack.pop()\n",
    "        z = continue_reduce(z_buffer, z_stack1, context)\n",
    "        stack.append(z)\n",
    "        \n",
    "    # Node with two parents\n",
    "    if(example_neuron.branch_order[node] == 2):\n",
    "        z_stack1 = stack.pop()\n",
    "        z_stack2 = stack.pop()\n",
    "        z = branch_reduce(z_buffer, z_stack1, z_stack2, context)\n",
    "        stack.append(z)\n",
    "        \n",
    "    node-=1\n",
    "\n",
    "z_buffer = encode_node(example_neuron, node, random_projection)\n",
    "stack.append(z_buffer)\n",
    "\n",
    "while len(stack) > 1:\n",
    "    context = 0. # tracker(context, stack[-1], z1)\n",
    "    \n",
    "    if len(stack) > 2:\n",
    "        z1 = stack.pop()    \n",
    "        z2 = stack.pop()\n",
    "        z3 = stack.pop()\n",
    "        z = branch_reduce(z1, z2, z3, context)\n",
    "        stack.append(z)\n",
    "    else:\n",
    "        z1 = stack.pop()\n",
    "        z2 = stack.pop()\n",
    "        z = continue_reduce(z1, z2, context)\n",
    "        stack.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -7544.89  19066.11    114.12]]\n"
     ]
    }
   ],
   "source": [
    "stack = np.array(stack)\n",
    "print stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7544.89,  19066.11,    114.12])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(example_neuron.location, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = np.pad(example_neuron.location, ((0, 0), (0, 10)), 'constant', constant_values=-999.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 408)\n",
      "(3, 418)\n"
     ]
    }
   ],
   "source": [
    "print example_neuron.location.shape\n",
    "print tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = np.pad(example_neuron.branch_order, (0, 10), 'constant', constant_values=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408,)\n",
      "(418,)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print example_neuron.branch_order.shape\n",
    "print tmp.shape\n",
    "print tmp[-11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_nodes = 40\n",
    "input_dim = 100\n",
    "train_iters = 5000\n",
    "batch_size = 32\n",
    "d_iters = 10\n",
    "lr_discriminator =  0.0005\n",
    "lr_generator = 0.01\n",
    "# train_loss = 'binary_crossentropy'\n",
    "train_loss = 'wasserstein_loss'\n",
    "\n",
    "rule = 'none'\n",
    "d_clip = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bundle(x):\n",
    "    return torch.t(torch.stack([x_ for x_ in x], 1)).squeeze()\n",
    "    # return torch.t(torch.stack([x_.pop() for x_ in x], 1)).squeeze()\n",
    "\n",
    "def unbundle(x):\n",
    "    if x is None:\n",
    "        return itertools.repeat(None)\n",
    "    return torch.split(torch.cat(x, 1), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def continue_lstm(stack1, buf, lstm_in):\n",
    "    u_, input_, forget_stack1_, forget_buf_, output_ = lstm_in.chunk(5, 1)\n",
    "    c = input_.sigmoid() * u_.tanh() + \\\n",
    "        forget_stack1_.sigmoid() * stack1 + \\\n",
    "        forget_buf_.sigmoid() * buf\n",
    "    h = output_.sigmoid() * c.tanh()\n",
    "    # print '(h, c)', h.size(), c.size()\n",
    "    return torch.cat([h.unsqueeze(2), c.unsqueeze(2)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def branch_lstm(stack1, stack2, buf, lstm_in):\n",
    "    u_, input_, forget_stack1_, forget_stack2_, forget_buf_, output_ = lstm_in.chunk(6, 1)\n",
    "    c = input_.sigmoid() * u_.tanh() + \\\n",
    "        forget_stack1_.sigmoid() * stack1 + \\\n",
    "        forget_stack2_.sigmoid() * stack2 + \\\n",
    "        forget_buf_.sigmoid() * buf\n",
    "    h = output_.sigmoid() * c.tanh()\n",
    "    # print '(h, c)', h.size(), c.size()\n",
    "    return torch.cat([h.unsqueeze(2), c.unsqueeze(2)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Reduce1(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, dim, tracker_dim):\n",
    "        super(Reduce1, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.tracker_dim = dim\n",
    "        self.stack1 = torch.nn.Linear(dim, 5 * dim)\n",
    "        self.buf = torch.nn.Linear(dim, 5 * dim, bias=False)\n",
    "        self.track = torch.nn.Linear(tracker_dim, 5 * dim, bias=False)\n",
    "            \n",
    "    def forward(self, stack1, buf, context):\n",
    "        if len(stack1) > 1:\n",
    "            stack1_, buf_ = bundle(stack1), bundle(buf)\n",
    "        else:\n",
    "            stack1_, buf_ = \\\n",
    "                stack1[-1].view(1, 2 * self.dim), buf[-1].view(1, 2 * self.dim)\n",
    "            print stack1[-1].size()\n",
    "            print stack1_.size()\n",
    "        if len(context) > 1:\n",
    "            context_ = bundle(context)\n",
    "        else:\n",
    "            context_ = context[-1].view(1, 2 * self.tracker_dim)\n",
    "        lstm_in = self.stack1(stack1_[:, :self.dim])\n",
    "        lstm_in += self.buf(buf_[:, :self.dim])\n",
    "        lstm_in += self.track(context_[:, :self.dim])\n",
    "        out = continue_lstm(stack1_[:, self.dim:], buf_[:, self.dim:], lstm_in)\n",
    "        print 'output of reduce1 is list of length', len(out), 'containing', out[0].size()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Reduce2(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, dim, tracker_dim):\n",
    "        super(Reduce2, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.tracker_dim = dim\n",
    "        self.stack1 = torch.nn.Linear(dim, 6 * dim)\n",
    "        self.stack2 = torch.nn.Linear(dim, 6 * dim, bias=False)\n",
    "        self.buf = torch.nn.Linear(dim, 6 * dim, bias=False)\n",
    "        self.track = torch.nn.Linear(tracker_dim, 6 * dim, bias=False)\n",
    "            \n",
    "    def forward(self, stack1, stack2, buf, context):\n",
    "        if len(stack1) > 1:\n",
    "            stack1_, stack2_, buf_ = bundle(stack1), bundle(stack2), bundle(buf)\n",
    "        else:\n",
    "            stack1_, stack2_, buf_ = \\\n",
    "                stack1[-1].view(1, 2 * self.dim), stack2[-1].view(1, 2 * self.dim), buf[-1].view(1, 2 * self.dim)\n",
    "        context_ = bundle(context)\n",
    "        lstm_in = self.stack1(stack1_[:, :self.dim])\n",
    "        lstm_in += self.stack2(stack2_[:, :self.dim])\n",
    "        lstm_in += self.buf(buf_[:, :self.dim])\n",
    "        lstm_in += self.track(context_[:, :self.dim])\n",
    "        out = branch_lstm(stack1_[:, self.dim:], stack2_[:, self.dim:], buf_[:, self.dim:], lstm_in)\n",
    "        print 'output of reduce2 is list of length', len(out), 'containing', out[0].size()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Tracker(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, dim, tracker_dim):\n",
    "        super(Tracker, self).__init__()\n",
    "        self.rnn = torch.nn.LSTMCell(4 * dim, tracker_dim)\n",
    "        self.dim = dim\n",
    "        self.tracker_dim = tracker_dim\n",
    "        self.context = None \n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.context = None\n",
    "\n",
    "    def forward(self, bufs, stacks):\n",
    "        buf = torch.t(torch.stack([buf[-1] for buf in bufs], 1).squeeze())\n",
    "        stack1 = torch.t(torch.stack([stack[-1] for stack in stacks], 1).squeeze())\n",
    "        x = torch.cat((stack1, buf), 1)\n",
    "        batch_size = x.size(0)\n",
    "        if self.context is None:\n",
    "            self.context = 2 * [Variable(torch.zeros(batch_size, self.tracker_dim))]\n",
    "        self.context = self.rnn(x, self.context)\n",
    "        res = unbundle(self.context)\n",
    "        print 'output of tracker is list of length', len(res), 'containing', res[0].size()\n",
    "        return unbundle(self.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NodeEncoder [node2vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NodeEncoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=3, hidden_dim=25, output_dim=100):\n",
    "        super(NodeEncoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.linear1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear2 = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_ = self.linear1(x)\n",
    "        h_ = torch.nn.Softsign()(h_)\n",
    "        h_ = self.linear2(h_)\n",
    "        c_ = Variable(torch.zeros(h_.size()))\n",
    "        y_pred = torch.cat([h_, c_], 1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TreeEncoder [tree2vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TreeEncoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dim=100,\n",
    "                 tracker_dim=100,\n",
    "                 node_input_dim=3,\n",
    "                 node_hidden_dim=25):\n",
    "        super(TreeEncoder, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.tracker_dim = tracker_dim\n",
    "        self.reduce1 = Reduce1(dim, tracker_dim)\n",
    "        self.reduce2 = Reduce2(dim, tracker_dim)\n",
    "        self.tracker = Tracker(dim, tracker_dim)\n",
    "        self.encoder = NodeEncoder(node_input_dim, node_hidden_dim, dim)\n",
    "        \n",
    "    def forward(self, buffers, commands):\n",
    "        encoded_buffers = [torch.t(self.encoder(torch.stack([buf for buf in buff], 0).squeeze())) for buff in buffers]\n",
    "        encoded_buffers = [list(buf.chunk(buf.size(1), 1)) for buf in encoded_buffers]\n",
    "        \n",
    "        # Initialize stack\n",
    "        stacks = [[buf[0]] for buf in encoded_buffers]\n",
    "\n",
    "        # Reset tracker state\n",
    "        self.tracker.reset_state()\n",
    "\n",
    "        # Loop through nodes\n",
    "        node = np.max([len(com) for com in commands])\n",
    "        while (node >= 1):\n",
    "\n",
    "            print node\n",
    "            # Update tracker states\n",
    "            tracker_states = self.tracker(encoded_buffers, stacks)\n",
    "            \n",
    "            stack00, stack11, stack21, stack22, = [], [], [], []\n",
    "            bufs1, bufs2, trackings1, trackings2 = [], [], [], []\n",
    "            batch = zip(commands, encoded_buffers, stacks, tracker_states)\n",
    "            for com, buf, stack, tracking in batch:    \n",
    "                if len(buf) > 0:\n",
    "                    # Read buffer and command\n",
    "                    b, c = buf.pop(), com[-1]\n",
    "                    print b.size()\n",
    "                    if c.data.numpy()[0] == 0:  # leaf node\n",
    "                        stack00.append(b)\n",
    "\n",
    "                    elif c.data.numpy()[0] == 1:  # node with one parent (continuation)\n",
    "                        bufs1.append(b)\n",
    "                        stack11.append(stack.pop())\n",
    "                        trackings1.append(tracking)\n",
    "\n",
    "                    elif c.data.numpy()[0] == 2: # node with two parents (branching)\n",
    "                        bufs2.append(b)\n",
    "                        stack21.append(stack.pop())\n",
    "                        stack22.append(stack.pop())\n",
    "                        trackings2.append(tracking)\n",
    "\n",
    "            if stack00:\n",
    "                print 'shift'\n",
    "                reduced0 = iter(stack00)\n",
    "                for com, stack in zip(commands, stacks):\n",
    "                    c = com[-1]\n",
    "                    if c.data.numpy()[0] == 0:\n",
    "                        com.pop()\n",
    "                        stack.append(next(reduced0))\n",
    "                        print 'stack length = ', len(stack)\n",
    "            if stack11:\n",
    "                print 'reduce1'\n",
    "                print '---------'\n",
    "                print '# reduce1 ops in this batch =', len(stack11)\n",
    "                reduced1 = iter(self.reduce1(stack11, bufs1, trackings1))\n",
    "                omg = 1\n",
    "                for com in commands:\n",
    "                    c = com[-1]\n",
    "                    if c.data.numpy()[0] == 1:\n",
    "                        omg += 1\n",
    "                for com, stack in zip(commands, stacks):\n",
    "                    c = com[-1]\n",
    "                    if c.data.numpy()[0] == 1:\n",
    "                        com.pop()\n",
    "                        stack.append(next(reduced1))\n",
    "                        print 'stack length = ', len(stack)\n",
    "            if stack22:\n",
    "                print 'reduce2'\n",
    "                reduced2 = iter(self.reduce2(stack21, stack22, bufs2, trackings2))\n",
    "                for com, stack in zip(commands, stacks):\n",
    "                    c = com[-1]\n",
    "                    if c.data.numpy()[0] == 2:\n",
    "                        com.pop()\n",
    "                        stack.append(next(reduced2))\n",
    "                        print 'stack length = ', len(stack)\n",
    "            node -= 1\n",
    "\n",
    "        # Process the remaining items in the stack\n",
    "        print 'processing remaining items in the stack'\n",
    "        \n",
    "        while(1):\n",
    "            stack11, stack21, stack22, = [], [], []\n",
    "            bufs1, bufs2, trackings1, trackings2 = [], [], [], []\n",
    "        \n",
    "            for stack, tracking in zip(stacks, tracker_states):\n",
    "                if len(stack) > 2:\n",
    "                    bufs1.append(stack.pop())\n",
    "                    stack11.append(stack.pop())\n",
    "                    trackings1.append(tracking)\n",
    "                elif len(stack) > 3:\n",
    "                    bufs2.append(stack.pop())\n",
    "                    stack21.append(stack.pop())\n",
    "                    stack22.append(stack.pop())\n",
    "                    trackings2.append(tracking)\n",
    "                    \n",
    "            if stack11:\n",
    "                reduced1 = iter(self.reduce1(stack11, bufs1, trackings1))\n",
    "                for com, stack in zip(commands, stacks):  # this logic won't work (coms are empty)\n",
    "                    if com == 1:\n",
    "                        stack.append(next(reduced1))\n",
    "            elif stack22:\n",
    "                reduced2 = iter(self.reduce2(stack21, stack22, bufs2, trackings2))\n",
    "                for com, stack in zip(commands, stacks): # this logic won't work (coms are empty)\n",
    "                    if com == 2:\n",
    "                        stack.append(next(reduced2))\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return torch.t(torch.stack([stack.pop() for stack in stacks], 1)).squeeze()\n",
    "        # return stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=100, n_classes=5):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.linear1 = torch.nn.Linear(input_dim, 100)\n",
    "        self.linear2 = torch.nn.Linear(100, 50)\n",
    "        self.linear3 = torch.nn.Linear(50, 10)\n",
    "        self.linear4 = torch.nn.Linear(10, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_ = self.linear1(x)\n",
    "        h_ = torch.nn.Softsign()(h_)\n",
    "        h_ = self.linear2(h_)\n",
    "        h_ = torch.nn.Softsign()(h_)\n",
    "        h_ = self.linear3(h_)\n",
    "        h_ = torch.nn.Softsign()(h_)\n",
    "        h_ = self.linear4(h_)\n",
    "        h_ = torch.nn.Softmax()(h_)\n",
    "        y_pred = h_\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "output of tracker is list of length 3 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "shift\n",
      "stack length =  2\n",
      "stack length =  2\n",
      "stack length =  2\n",
      "10\n",
      "output of tracker is list of length 3 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "shift\n",
      "stack length =  3\n",
      "stack length =  3\n",
      "stack length =  3\n",
      "9\n",
      "output of tracker is list of length 3 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "reduce2\n",
      "output of reduce2 is list of length 3 containing torch.Size([200, 1])\n",
      "stack length =  2\n",
      "stack length =  2\n",
      "stack length =  2\n",
      "8\n",
      "output of tracker is list of length 3 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "shift\n",
      "stack length =  3\n",
      "stack length =  3\n",
      "stack length =  3\n",
      "7\n",
      "output of tracker is list of length 3 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "reduce1\n",
      "output of reduce1 is list of length 3 containing torch.Size([200, 1])\n",
      "3 3\n",
      "c =  Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "stack length =  3\n",
      "c =  Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "stack length =  3\n",
      "c =  Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "stack length =  3\n",
      "6\n",
      "output of tracker is list of length 3 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "reduce2\n",
      "output of reduce2 is list of length 3 containing torch.Size([200, 1])\n",
      "stack length =  2\n",
      "stack length =  2\n",
      "stack length =  2\n",
      "5\n",
      "output of tracker is list of length 3 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "shift\n",
      "stack length =  3\n",
      "stack length =  3\n",
      "stack length =  3\n",
      "4\n",
      "output of tracker is list of length 3 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "shift\n",
      "stack length =  4\n",
      "stack length =  4\n",
      "stack length =  4\n",
      "3\n",
      "output of tracker is list of length 3 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "reduce2\n",
      "output of reduce2 is list of length 3 containing torch.Size([200, 1])\n",
      "stack length =  3\n",
      "stack length =  3\n",
      "stack length =  3\n",
      "2\n",
      "output of tracker is list of length 3 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "reduce1\n",
      "output of reduce1 is list of length 3 containing torch.Size([200, 1])\n",
      "3 3\n",
      "c =  Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "stack length =  3\n",
      "c =  Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "stack length =  3\n",
      "c =  Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "stack length =  3\n",
      "1\n",
      "output of tracker is list of length 3 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "reduce2\n",
      "output of reduce2 is list of length 3 containing torch.Size([200, 1])\n",
      "stack length =  2\n",
      "stack length =  2\n",
      "stack length =  2\n",
      "processing remaining items in the stack\n",
      "torch.Size([3, 200]) torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "T = TreeEncoder(dim=100,\n",
    "                tracker_dim=100,\n",
    "                node_input_dim=3,\n",
    "                node_hidden_dim=25)\n",
    "D = Classifier(input_dim=100,\n",
    "               n_classes=5)\n",
    "\n",
    "buffers = [Variable(torch.randn(3, 11)),\n",
    "           Variable(torch.randn(3, 11)),\n",
    "           Variable(torch.randn(3, 11))]\n",
    "buffers = [list(buf.chunk(buf.size(1), 1)) for buf in buffers]\n",
    "\n",
    "command1 = Variable(torch.Tensor([2, 1, 2, 0, 0, 2, 1, 0, 2, 0, 0]))\n",
    "command2 = Variable(torch.Tensor([2, 1, 2, 0, 0, 2, 1, 0, 2, 0, 0]))\n",
    "command3 = Variable(torch.Tensor([2, 1, 2, 0, 0, 2, 1, 0, 2, 0, 0]))\n",
    "commands = [command1, command2, command3]\n",
    "commands = [list(com.split(1)) for com in commands]\n",
    "\n",
    "z = T(buffers, commands)\n",
    "d = D(z[:, :input_dim])\n",
    "\n",
    "print z.size() , d.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715\n",
      "output of tracker is list of length 2 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "shift\n",
      "stack length =  2\n",
      "stack length =  2\n",
      "714\n",
      "output of tracker is list of length 2 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "reduce1\n",
      "output of reduce1 is list of length 2 containing torch.Size([200, 1])\n",
      "2 2\n",
      "c =  Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "stack length =  2\n",
      "c =  Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "stack length =  2\n",
      "713\n",
      "output of tracker is list of length 2 containing torch.Size([1, 200])\n",
      "torch.Size([200, 1])\n",
      "torch.Size([200, 1])\n",
      "shift\n",
      "stack length =  3\n",
      "reduce1\n",
      "torch.Size([200, 1])\n",
      "torch.Size([1, 200])\n",
      "output of reduce1 is list of length 1 containing torch.Size([200, 1])\n",
      "2 2\n",
      "c =  Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "stack length =  2\n",
      "c =  Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-89bab7f7ee24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcommands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcommands\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pavanramkumar/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-194-1a0e15128c80>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, buffers, commands)\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                         \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                         \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                         \u001b[0;32mprint\u001b[0m \u001b[0;34m'stack length = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstack22\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neuron0 = McNeuron.Neuron(input_file=training_data['X'][0][:, :],\n",
    "                          input_format=\"Matrix of swc\")\n",
    "\n",
    "neuron1 = McNeuron.Neuron(input_file=training_data['X'][2][:, :],\n",
    "                          input_format=\"Matrix of swc\")\n",
    "\n",
    "\n",
    "buffers = [Variable(torch.Tensor(neuron0.location)),\n",
    "           Variable(torch.Tensor(neuron1.location))]\n",
    "buffers = [list(buf.chunk(buf.size(1), 1)) for buf in buffers]\n",
    "\n",
    "commands = [Variable(torch.Tensor(neuron0.branch_order)),\n",
    "            Variable(torch.Tensor(neuron1.branch_order))]\n",
    "\n",
    "commands = [list(com.split(1)) for com in commands]\n",
    "\n",
    "z = T(buffers, commands)\n",
    "d = D(z[:, :input_dim])\n",
    "\n",
    "print z.size() , d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commands[0][-1].data.numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reset_grad(nets):\n",
    "    for net in nets:\n",
    "        net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G_shared' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-0273b3faea03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_shared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mG_solver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mD_solver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_discriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'G_shared' is not defined"
     ]
    }
   ],
   "source": [
    "G_params = (list(G_shared.parameters()) + list(Gg.parameters()) + list(Gm.parameters()))\n",
    "\n",
    "G_solver = optim.RMSprop(G_params, lr=lr_generator)\n",
    "D_solver = optim.RMSprop(D.parameters(), lr=lr_discriminator)\n",
    "\n",
    "for it in range(train_iters):\n",
    "    list_d_loss = list()\n",
    "    for _ in range(d_iters):\n",
    "        \n",
    "        # Sample real data from training set\n",
    "        g_real, m_real = next(batch_utils.get_batch(training_data,\n",
    "                                                    batch_size,\n",
    "                                                    n_nodes))\n",
    "        x_real = np.concatenate((g_real, m_real), 2)\n",
    "        x_real = x_real.astype(float)\n",
    "        x_real = Variable(torch.Tensor(x_real), requires_grad=True)\n",
    "\n",
    "        # Sample fake data from generators\n",
    "        z = Variable(torch.randn(batch_size, input_dim))\n",
    "        g_fake, m_fake = Gg(G_shared(z)), Gm(G_shared(z))\n",
    "        x_fake = torch.cat([g_fake, m_fake], 2)\n",
    "        \n",
    "        # Train discriminator [forward-loss-backward-update]\n",
    "        d_real, d_fake = D(x_real), D(x_fake)\n",
    "        d_loss = -(torch.mean(d_real) - torch.mean(d_fake))\n",
    "        d_loss.backward()\n",
    "        D_solver.step()\n",
    "\n",
    "        # Weight clipping\n",
    "        for p in D.parameters():\n",
    "            p.data.clamp_(-d_clip, d_clip)\n",
    "\n",
    "        # Housekeeping\n",
    "        list_d_loss.append(d_loss.data.numpy()[0])\n",
    "        nets = [G_shared, Gg, Gm, D]\n",
    "        reset_grad(nets)\n",
    "        \n",
    "    # Sample fake data from generators\n",
    "    z = Variable(torch.randn(batch_size, input_dim))\n",
    "    g_fake, m_fake = Gg(G_shared(z)), Gm(G_shared(z))\n",
    "    x_fake = torch.cat([g_fake, m_fake], 2)        \n",
    "    d_fake = D(x_fake)\n",
    "\n",
    "    # Train generators [forward-loss-backward-update]\n",
    "    g_loss = -torch.mean(d_fake)\n",
    "    g_loss.backward()\n",
    "    \n",
    "    for p in G_shared.parameters():\n",
    "        p.grad.data = 0.5 * p.grad.data\n",
    "    \n",
    "    G_solver.step()\n",
    "\n",
    "    # Housekeeping\n",
    "    nets = [S, G, M, D]\n",
    "    reset_grad(nets)\n",
    "\n",
    "    print(d_loss.data.numpy())\n",
    "    print(g_loss.data.numpy())\n",
    "\n",
    "    neuron_object = \\\n",
    "        plot_utils.plot_example_neuron_from_parent(\n",
    "            g_real[0, :, :],\n",
    "            m_real[0, :, :])\n",
    "\n",
    "    neuron_object = \\\n",
    "        plot_utils.plot_example_neuron_from_parent(\n",
    "            g_fake.data.numpy()[0, :, :],\n",
    "            m_fake.data.numpy()[0, :, :])\n",
    "        \n",
    "    plt.plot(np.squeeze(g_fake.data.numpy()[0, :, :]))\n",
    "\n",
    "    plot_utils.plot_adjacency(m_real[0:2, :, :],\n",
    "                              m_real[0:2, :, :],\n",
    "                              m_fake.data.numpy()[0:2, :, :])\n",
    "\n",
    "    plot_utils.plot_loss_trace(list_d_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-f0dc1d491274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# x_inter = eps * x_real + (1. - eps) * x_fake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_inter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_real\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_inter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgrad_pen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_norm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'grad'"
     ]
    }
   ],
   "source": [
    "eps = Variable(torch.rand(batch_size, 1))\n",
    "# x_inter = eps * x_real + (1. - eps) * x_fake\n",
    "x_inter = x_real\n",
    "grad = torch.grad(D(x_inter), [x_inter])\n",
    "grad_norm = torch.sqrt(torch.sum((grad) ** 2, 1))\n",
    "grad_pen = lam * torch.mean(grad_norm - 1.) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
